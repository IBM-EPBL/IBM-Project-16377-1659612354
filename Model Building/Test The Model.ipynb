{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f407dcf-ca6b-42b3-a812-cd768765ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\HP\\Desktop\\data_set\\TRAIN_SET',target_size = (64,64) ,batch_size = 5,color_mode='rgb',class_mode = 'sparse')\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\HP\\Desktop\\data_set\\TEST_SET-20221101T044129Z-001\\TEST_SET',target_size = (64,64) ,batch_size = 5,color_mode='rgb',class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f238dd-ba29-4283-a6b7-f317818a84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computatio\n",
    "from tensorflow.keras.models import Sequential #it is a palin stack of layer \n",
    "from tensorflow.keras.layers import Layer #Alayer consists of a tensor-in tensor-out computation function\n",
    "from tensorflow.keras.layers import Dense,Flatten #flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #convolution layer , MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914033c-1881-460a-a215-1c1d561a7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecea3f-076d-4c9f-b8c3-7b484967ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9b08b-de5e-4059-bf58-b049bb252082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a4a8b-e55d-46c1-ae96-a8631a1b9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a9200-04b5-456b-be89-82bff77b67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dense(units=128,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc65596-158d-4bf5-a103-e90d73668b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e294ac6-2f84-4b43-9c93-d590af58d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75ea2f-b3f8-4fad-9b60-7204de728cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "generator=x_train,steps_per_epoch=len(x_train),\n",
    "epochs=20,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891583a-6b79-4a9d-b361-30bfc7829ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1c3b7-91bf-4512-951f-3c79c5e9d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556a8af-a11b-467b-a2de-68f40a01f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"nutrition.h5\")\n",
    "labels=['APPLES','BANANA','ORANGE','PINEAPPLE','WATERMELON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4ab77-92a7-45ad-a785-322e32262b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(r\"C:\\Users\\HP\\Desktop\\data_set\\TEST_SET-20221101T044129Z-001\\TEST_SET\\APPLES\\3_100.jpg\",grayscale=False,target_size=(64,64))\n",
    "x = img_to_array(img)\n",
    "x=np.expand_dims(x,[0])\n",
    "pred = model.predict(x)\n",
    "y_class = answer.argmax(axis=-1)\n",
    "y = \" \".join(str(x) for x in y_class)\n",
    "y = int(y)\n",
    "res = labels[y]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170ae34-5f6b-4c9a-9ca4-9d6a887ac647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3cec3-9faa-4332-b837-8dafe8fdc4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb285750-54ba-4e28-bf63-afbf31773f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
